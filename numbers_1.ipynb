{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first experiment that I want to do involves the most simple identification of facts within content-free tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from nnsight import CONFIG\n",
    "from nnsight import LanguageModel\n",
    "import nnsight\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing from my own code \n",
    "from activation_transplanting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the api_key\n",
    "CONFIG.set_default_api_key(os.environ.get('NDIF_KEY'))\n",
    "\n",
    "# read the hf token\n",
    "os.environ['HF_TOKEN'] = os.environ.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDIF_models = [\n",
    "    \"meta-llama/Meta-Llama-3.1-405B-Instruct\",\n",
    "    \"meta-llama/Meta-Llama-3.1-8B\",\n",
    "    \"meta-llama/Meta-Llama-3.1-70B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "] \n",
    "\n",
    "# inexaustive list\n",
    "non_NDIF_models = [\n",
    "    \"meta-llama/Meta-Llama-3.1-8B\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompts\n",
    "\n",
    "# instruct examples\n",
    "prompt_example_1 = \"<|begin▁of▁sentence|>\\n\" \\\n",
    "         \"<|start_header_id|>user<|end_header_id|>\\n\\n\" \\\n",
    "         \"Hello, how are you? <|eot_id|>\\n\" \\\n",
    "         \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "\n",
    "prompt_example_2 = \"<|start_header_id|>system<|end_header_id|>\\n\\n<|eot_id|>\\n\" \\\n",
    "                \"<|start_header_id|>user<|end_header_id|>\\n\\n\" \\\n",
    "                \"Answer the following in one word: What is the tallest mountain in the world?<|eot_id|>\\n\" \\\n",
    "                \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "\n",
    "# Base model examples \n",
    "prompt_example_3 = \"\\nUser: What's the capital of France?\\n\\nAssistant:\"\n",
    "\n",
    "# Reasoning examples \n",
    "prompt_example_4 = \"<｜User｜>Robert has three apples, and then gets one more. How many apples does he have? Respond in a single word.<｜Assistant｜>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numbers Experiment 1\n",
    "\n",
    "We'll be simply trying to identify the presence of stored numbers at particular tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_simple_number_string(num, mode='base'):\n",
    "    prefix = \"Word Problem Setup:\"\n",
    "    \n",
    "    # Define possible components for the problem\n",
    "    intros = [\"A man has \", \"A boy has \", \"Steven has \", \"Robert has \", \n",
    "             \"A woman has \", \"A girl has \", \"Sarah has \", \"Emily has \",\n",
    "             \"Alex has \", \"Jordan has \", \"Taylor has \", \"Sam has \"]\n",
    "    \n",
    "    numbers = [\"one\", \"two\", \"three\", \"four\", \"five\", \n",
    "              \"six\", \"seven\", \"eight\", \"nine\", \"ten\"]\n",
    "    \n",
    "    objects = [(\"apple\", \"apples\"), (\"banana\", \"bananas\"), (\"orange\", \"oranges\"),\n",
    "              (\"peach\", \"peaches\"), (\"pear\", \"pears\"), (\"grape\", \"grapes\"),\n",
    "              (\"strawberry\", \"strawberries\"), (\"blueberry\", \"blueberries\"),\n",
    "              (\"mango\", \"mangoes\"), (\"kiwi\", \"kiwis\"), (\"plum\", \"plums\")]\n",
    "    \n",
    "    suffixes = [\n",
    "        \"when he leaves the store\", \"when he leaves the shop\", \n",
    "        \"when he leaves the grocery store\", \"when he leaves the market\",\n",
    "        \"when she leaves the store\", \"when she leaves the shop\",\n",
    "        \"when she leaves the grocery store\", \"when she leaves the market\",\n",
    "        \"after shopping\", \"after grocery shopping\", \"after visiting the supermarket\"\n",
    "    ]\n",
    "    \n",
    "    ending = \".\\n\\n\"\n",
    "    \n",
    "    # Choose random components\n",
    "    intro = random.choice(intros)\n",
    "    \n",
    "    # Select appropriate number word and object form based on num\n",
    "    if 1 <= num <= 10:\n",
    "        number_word = numbers[num-1]\n",
    "        obj = random.choice(objects)\n",
    "        # Use singular or plural form based on num\n",
    "        object_word = obj[0] if num == 1 else obj[1]\n",
    "    else:\n",
    "        # For numbers > 10, just use the numeric form\n",
    "        number_word = str(num)\n",
    "        obj = random.choice(objects)\n",
    "        object_word = obj[1]  # Always use plural\n",
    "    \n",
    "    suffix = random.choice(suffixes)\n",
    "    \n",
    "    # Make pronoun in suffix match the intro person's implied gender\n",
    "    if (\"man\" in intro or \"boy\" in intro or \"Steven\" in intro or \"Robert\" in intro) and \"she\" in suffix:\n",
    "        suffix = suffix.replace(\"she\", \"he\")\n",
    "    elif (\"woman\" in intro or \"girl\" in intro or \"Sarah\" in intro or \"Emily\" in intro) and \"he\" in suffix:\n",
    "        suffix = suffix.replace(\"he\", \"she\")\n",
    "    \n",
    "    # Assemble the full problem\n",
    "    \n",
    "    if mode=='base':\n",
    "        problem = f\"{prefix} {intro}{number_word} {object_word} {suffix}{ending}\"\n",
    "    elif mode == 'instruct':\n",
    "        problem = f\"<|start_header_id|>user<|end_header_id|>\\n\\n{prefix} {intro}{number_word} {object_word} {suffix}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "    \n",
    "    return problem, obj[1]\n",
    "\n",
    "\n",
    "def extract_final_logits(\n",
    "        tk,\n",
    "        source_strings: list[str],\n",
    "        target_strings: list[str],\n",
    "        target_substring: str,\n",
    "        occurrence_index: int = 0,\n",
    "        num_prev: int = 0,\n",
    "        num_fut: int = 0,\n",
    "        transplant_strings: tuple[str] = (\"residual\"),\n",
    "    ) -> list[str]:\n",
    "        \"\"\"\n",
    "        extract the logits produced at the final position of target_strings\n",
    "        \"\"\"\n",
    "        assert num_prev >= 0\n",
    "        assert num_fut >= 0\n",
    "\n",
    "        # Extract newline activations from source strings\n",
    "        activation_containers, source_newline_indices = (\n",
    "            tk.extract_newline_activations(\n",
    "                strings=source_strings,\n",
    "                target_substring=target_substring,\n",
    "                occurrence_index=occurrence_index,\n",
    "                transplant_strings=transplant_strings,\n",
    "                num_prev=num_prev,\n",
    "                num_fut=num_fut,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(\"source_newline_indices\", source_newline_indices)\n",
    "        output_logits = []\n",
    "\n",
    "        # Process each target string with corresponding source activations\n",
    "        for target_string, activation_container, source_newline_index in zip(\n",
    "            target_strings, activation_containers, source_newline_indices\n",
    "        ):\n",
    "            print(\"source_newline_index\", source_newline_index)\n",
    "            act = activation_container.get_token_by_index(\n",
    "                source_newline_index\n",
    "            )\n",
    "            print(act)\n",
    "            \n",
    "            print(vars(activation_container))\n",
    "\n",
    "            final_logits = tk.evaluate_with_transplanted_activity(\n",
    "                target_string=target_string,\n",
    "                target_substring=target_substring,\n",
    "                activation_container=activation_container,\n",
    "                source_token_index=source_newline_index,\n",
    "                occurrence_index=occurrence_index,\n",
    "                transplant_strings=transplant_strings,\n",
    "                num_prev=num_prev,\n",
    "                num_fut=num_fut,\n",
    "            )\n",
    "            output_logits.append(final_logits)\n",
    "        \n",
    "        return output_logits\n",
    "\n",
    "def predict_number_probs(logits, llama):\n",
    "    logit_values = []\n",
    "    # add a prefix t get the token in context\n",
    "    prefix = \".\\n\\nThey have\"\n",
    "    numbers = [' one', ' two', ' three', ' four', ' five', ' six', ' seven', ' eight', ' nine', ' ten']\n",
    "    \n",
    "    for i, n in enumerate(numbers):\n",
    "        idx = llama.tokenizer.encode(prefix+n)[-1]\n",
    "        assert idx is not None\n",
    "        logit_values.append(logits[idx].float())\n",
    "    \n",
    "    all_probs = torch.nn.functional.softmax(torch.tensor(logit_values), dim=0)\n",
    "\n",
    "    # Sum probabilities for word forms and digit forms\n",
    "    return all_probs#[:10]+all_probs[10:]\n",
    "\n",
    "def evaluate_number_probs(strings, items, tk, target_substring=\".\\n\\n\"):\n",
    "    \"\"\" \n",
    "    for each string, we'll evaluate the probabilities of numbers\n",
    "    \"\"\"\n",
    "    question_strings = [f\"{target_substring} Therefore, the total number of {item} they currently had was\" for item, s in zip(items, strings)]\n",
    "\n",
    "    for s, q in zip(strings, question_strings):\n",
    "        print(s, q)\n",
    "\n",
    "    final_logits = extract_final_logits(\n",
    "        tk,\n",
    "        source_strings=strings,\n",
    "        target_strings=question_strings,\n",
    "        target_substring=target_substring,\n",
    "        occurrence_index= -1,\n",
    "        num_prev = 0,\n",
    "        num_fut = 0,\n",
    "        transplant_strings= (\"residual\"),\n",
    "    )\n",
    "    \n",
    "    extracted_probs = []\n",
    "    for logits in final_logits:\n",
    "        extracted_probs.append(predict_number_probs(logits, tk.llama))\n",
    "    \n",
    "    return extracted_probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple_number_experiment(tk, num, number_samples, target_substring=\".\\n\\n\", mode='base'):\n",
    "    \"\"\" \n",
    "    Choose a single num to use to generate sentences with \n",
    "    then generate number_samples with it\n",
    "\n",
    "    for each run evaluate_number_probs(strings, tk, target_substring)\n",
    "    to see the probability distribution over next numbers\n",
    "    \"\"\"\n",
    "    string_samples, items = zip(*[\n",
    "        generate_random_simple_number_string(num, mode=mode) for _ in range(number_samples)\n",
    "    ])\n",
    "\n",
    "    extracted_probs = evaluate_number_probs(string_samples, items, tk, target_substring=target_substring)\n",
    "\n",
    "    # now average over each \n",
    "    tot = 0\n",
    "    out=None\n",
    "    for p in extracted_probs:\n",
    "        if out is None:\n",
    "            out=p \n",
    "        else:\n",
    "            out+=p\n",
    "        \n",
    "        tot+=1\n",
    "    \n",
    "    return out.numpy()/tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Problem Setup: A man has ten apples when he leaves the market.\n",
      "\n",
      " .\n",
      "\n",
      " Therefore, the total number of apples they currently had was\n",
      "extracting token activations\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Connection error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# commented out for now\u001b[39;00m\n\u001b[0;32m     14\u001b[0m tk \u001b[38;5;241m=\u001b[39m LLamaExamineToolkit(\n\u001b[0;32m     15\u001b[0m     llama_model\u001b[38;5;241m=\u001b[39mllama, \n\u001b[0;32m     16\u001b[0m     remote\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# use NDIF\u001b[39;00m\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m \u001b[43mrun_simple_number_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtarget_substring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m, in \u001b[0;36mrun_simple_number_experiment\u001b[1;34m(tk, num, number_samples, target_substring, mode)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mChoose a single num to use to generate sentences with \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mthen generate number_samples with it\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mto see the probability distribution over next numbers\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m string_samples, items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m     10\u001b[0m     generate_random_simple_number_string(num, mode\u001b[38;5;241m=\u001b[39mmode) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_samples)\n\u001b[0;32m     11\u001b[0m ])\n\u001b[1;32m---> 13\u001b[0m extracted_probs \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_number_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_substring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_substring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# now average over each \u001b[39;00m\n\u001b[0;32m     16\u001b[0m tot \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[14], line 142\u001b[0m, in \u001b[0;36mevaluate_number_probs\u001b[1;34m(strings, items, tk, target_substring)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(strings, question_strings):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mprint\u001b[39m(s, q)\n\u001b[1;32m--> 142\u001b[0m final_logits \u001b[38;5;241m=\u001b[39m \u001b[43mextract_final_logits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion_strings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_substring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_substring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43moccurrence_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_prev\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_fut\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransplant_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresidual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m extracted_probs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logits \u001b[38;5;129;01min\u001b[39;00m final_logits:\n",
      "Cell \u001b[1;32mIn[14], line 78\u001b[0m, in \u001b[0;36mextract_final_logits\u001b[1;34m(tk, source_strings, target_strings, target_substring, occurrence_index, num_prev, num_fut, transplant_strings)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m num_fut \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Extract newline activations from source strings\u001b[39;00m\n\u001b[0;32m     77\u001b[0m activation_containers, source_newline_indices \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 78\u001b[0m     \u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_newline_activations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_strings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_substring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_substring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43moccurrence_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moccurrence_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransplant_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransplant_strings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_prev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_prev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_fut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_fut\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_newline_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m, source_newline_indices)\n\u001b[0;32m     89\u001b[0m output_logits \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\mech_interp_research\\activation_transplanting.py:565\u001b[0m, in \u001b[0;36mLLamaExamineToolkit.extract_newline_activations\u001b[1;34m(self, strings, target_substring, occurrence_index, transplant_strings, num_prev, num_fut)\u001b[0m\n\u001b[0;32m    562\u001b[0m source_token_indices \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Start tracing for activation capture\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtracer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mac\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_containers\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcutoff_string\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcutoff_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\intervention\\contexts\\interleaving.py:96\u001b[0m, in \u001b[0;36mInterleavingTracer.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoker\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39m_envoy\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\tracing\\contexts\\tracer.py:25\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglobals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalTracingContext\n\u001b[0;32m     23\u001b[0m GlobalTracingContext\u001b[38;5;241m.\u001b[39mtry_deregister(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\tracing\\contexts\\base.py:82\u001b[0m, in \u001b[0;36mContext.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m     78\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m     80\u001b[0m graph\u001b[38;5;241m.\u001b[39malive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\intervention\\backends\\remote.py:77\u001b[0m, in \u001b[0;36mRemoteBackend.__call__\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph: Graph):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocking:\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m         \u001b[38;5;66;03m# Do blocking request.\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocking_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m         \u001b[38;5;66;03m# Otherwise we are getting the status / result of the existing job.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnon_blocking_request(graph)\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\intervention\\backends\\remote.py:280\u001b[0m, in \u001b[0;36mRemoteBackend.blocking_request\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# We need to do some processing / optimizations on both the graph were sending remotely\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# and our local intervention graph. In order handle the more complex Protocols for streaming.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Create a socketio connection to the server.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m socketio\u001b[38;5;241m.\u001b[39mSimpleClient(reconnection_attempts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m sio:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# Connect\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mws_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocketio_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/ws/socket.io\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwebsocket\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m     remote_graph \u001b[38;5;241m=\u001b[39m preprocess(graph)\n\u001b[0;32m    289\u001b[0m     data, headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(remote_graph)\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\socketio\\simple_client.py:82\u001b[0m, in \u001b[0;36mSimpleClient.connect\u001b[1;34m(self, url, headers, auth, transports, namespace, socketio_path, wait_timeout)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_buffer\u001b[38;5;241m.\u001b[39mappend([event, \u001b[38;5;241m*\u001b[39margs])\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_event\u001b[38;5;241m.\u001b[39mset()\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtransports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransports\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msocketio_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msocketio_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\socketio\\client.py:159\u001b[0m, in \u001b[0;36mClient.connect\u001b[1;34m(self, url, headers, auth, transports, namespaces, socketio_path, wait, wait_timeout, retry)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meio\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnected\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    158\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mConnectionError(exc\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_event\u001b[38;5;241m.\u001b[39mwait(timeout\u001b[38;5;241m=\u001b[39mwait_timeout):\n",
      "\u001b[1;31mConnectionError\u001b[0m: Connection error"
     ]
    }
   ],
   "source": [
    "# choose a model \n",
    "llama_model_string = \"meta-llama/Meta-Llama-3.1-70B\"\n",
    "# remote = use NDIF\n",
    "remote = True \n",
    "\n",
    "if remote and (llama_model_string not in NDIF_models):\n",
    "    remote = False \n",
    "    print(\"Model not available on NDIF\")\n",
    "\n",
    "# load a model\n",
    "llama = LanguageModel(llama_model_string)\n",
    "\n",
    "# commented out for now\n",
    "tk = LLamaExamineToolkit(\n",
    "    llama_model=llama, \n",
    "    remote=True, # use NDIF\n",
    ")\n",
    "run_simple_number_experiment(tk, num=10, number_samples=1,target_substring='.\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Word Problem Setup: Sam has ten kiwis when he leaves the market<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      " <|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      " Therefore, the total number of kiwis they currently had was\n",
      "extracting token activations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 22:09:34,620 430a079e-a839-4a72-9a27-a012736f91d4 - RECEIVED: Your job has been received and is waiting approval.\n",
      "2025-03-14 22:09:35,129 430a079e-a839-4a72-9a27-a012736f91d4 - APPROVED: Your job was approved and is waiting to be run.\n"
     ]
    }
   ],
   "source": [
    "# choose a model \n",
    "llama_model_string = \"meta-llama/Meta-Llama-3.1-405B-Instruct\"\n",
    "# remote = use NDIF\n",
    "remote = True \n",
    "\n",
    "if remote and (llama_model_string not in NDIF_models):\n",
    "    remote = False \n",
    "    print(\"Model not available on NDIF\")\n",
    "\n",
    "# load a model\n",
    "llama = LanguageModel(llama_model_string)\n",
    "\n",
    "# commented out for now\n",
    "tk = LLamaExamineToolkit(\n",
    "    llama_model=llama, \n",
    "    remote=True, # use NDIF\n",
    ")\n",
    "\n",
    "run_simple_number_experiment(tk, num=10, number_samples=1,target_substring='<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n', mode='instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Word Problem Setup: A woman has ten oranges when he leaves the market.\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_simple_number_string(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWord Problem Setup: A woman has ten oranges when he leaves the market.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m The total number of oranges was \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtracer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mllama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\intervention\\contexts\\interleaving.py:96\u001b[0m, in \u001b[0;36mInterleavingTracer.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoker\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39m_envoy\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\tracing\\contexts\\tracer.py:25\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglobals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalTracingContext\n\u001b[0;32m     23\u001b[0m GlobalTracingContext\u001b[38;5;241m.\u001b[39mtry_deregister(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\tracing\\contexts\\base.py:82\u001b[0m, in \u001b[0;36mContext.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m     78\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m     80\u001b[0m graph\u001b[38;5;241m.\u001b[39malive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\intervention\\backends\\remote.py:77\u001b[0m, in \u001b[0;36mRemoteBackend.__call__\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph: Graph):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocking:\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m         \u001b[38;5;66;03m# Do blocking request.\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocking_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m         \u001b[38;5;66;03m# Otherwise we are getting the status / result of the existing job.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnon_blocking_request(graph)\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\intervention\\backends\\remote.py:294\u001b[0m, in \u001b[0;36mRemoteBackend.blocking_request\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m    291\u001b[0m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sio\u001b[38;5;241m.\u001b[39msid\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# Submit request via\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m LocalContext\u001b[38;5;241m.\u001b[39mset(\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_send(\u001b[38;5;241m*\u001b[39margs, job_id\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mid, sio\u001b[38;5;241m=\u001b[39msio)\n\u001b[0;32m    298\u001b[0m )\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;66;03m# Loop until\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\intervention\\backends\\remote.py:201\u001b[0m, in \u001b[0;36mRemoteBackend.submit_request\u001b[1;34m(self, data, headers)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mreason\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(msg)\n",
      "\u001b[1;31mConnectionError\u001b[0m: Internal Server Error"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with llama.generate(\n",
    "            'Word Problem Setup: A woman has ten oranges when he leaves the market.\\n\\n The total number of oranges was ',\n",
    "            max_new_tokens=20,\n",
    "            remote=True,\n",
    "        ) as tracer:\n",
    "        out = llama.generator.output.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 17:04:25,407 003a8792-56b6-4057-9a44-6d46f24a10b7 - RECEIVED: Your job has been received and is waiting approval.\n",
      "2025-03-14 17:04:25,927 003a8792-56b6-4057-9a44-6d46f24a10b7 - APPROVED: Your job was approved and is waiting to be run.\n",
      "2025-03-14 17:04:27,093 003a8792-56b6-4057-9a44-6d46f24a10b7 - RUNNING: Your job has started running.\n",
      "2025-03-14 17:04:27,652 003a8792-56b6-4057-9a44-6d46f24a10b7 - COMPLETED: Your job has been completed.\n",
      "Downloading result: 100%|██████████| 1.31k/1.31k [00:00<00:00, 48.8kB/s]\n"
     ]
    }
   ],
   "source": [
    "prompt = 'The Eiffel Tower is in the city of'\n",
    "n_new_tokens = 3\n",
    "with llama.generate(prompt, max_new_tokens=n_new_tokens, remote=True) as tracer:\n",
    "    out = llama.generator.output.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>Word Problem Setup: A woman has ten oranges when he leaves the market.\\n\\n The total number of oranges was 10. A woman has ten oranges when he leaves the market. He gives three to his daughter.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama.tokenizer.decode(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting token activations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 17:24:11,486 7a1970e4-1246-42eb-a17f-bbc072cfc38b - RECEIVED: Your job has been received and is waiting approval.\n",
      "2025-03-14 17:24:11,930 7a1970e4-1246-42eb-a17f-bbc072cfc38b - APPROVED: Your job was approved and is waiting to be run.\n",
      "2025-03-14 17:24:12,520 7a1970e4-1246-42eb-a17f-bbc072cfc38b - RUNNING: Your job has started running.\n",
      "2025-03-14 17:24:14,806 7a1970e4-1246-42eb-a17f-bbc072cfc38b - COMPLETED: Your job has been completed.\n",
      "Downloading result: 100%|██████████| 21.3M/21.3M [00:02<00:00, 10.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating with transplant\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m outputs\u001b[38;5;241m=\u001b[39m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransplant_newline_activities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWord Problem Setup: A woman has ten oranges when he leaves the market.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m She has \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWord Problem Setup: A woman has ten oranges when he leaves the market.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m She has \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_substring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43moccurrence_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_prev\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_fut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransplant_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresidual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\mech_interp_research\\activation_transplanting.py:792\u001b[0m, in \u001b[0;36mtransplant_newline_activities\u001b[1;34m(self, source_strings, target_strings, num_new_tokens, target_substring, occurrence_index, num_prev, num_fut, transplant_strings)\u001b[0m\n\u001b[0;32m    787\u001b[0m output_strings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Process each target string with corresponding source activations\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_string, activation_container, source_newline_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    791\u001b[0m     target_strings, activation_containers, source_newline_indices\n\u001b[1;32m--> 792\u001b[0m ):\n\u001b[0;32m    793\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_with_transplanted_activity(\n\u001b[0;32m    794\u001b[0m         target_string\u001b[38;5;241m=\u001b[39mtarget_string,\n\u001b[0;32m    795\u001b[0m         target_substring\u001b[38;5;241m=\u001b[39mtarget_substring,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    802\u001b[0m         num_fut\u001b[38;5;241m=\u001b[39mnum_fut,\n\u001b[0;32m    803\u001b[0m     )\n\u001b[0;32m    804\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllama\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(tokens[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\mech_interp_research\\activation_transplanting.py:672\u001b[0m, in \u001b[0;36mgenerate_with_transplanted_activity\u001b[1;34m(self, target_string, target_substring, source_token_index, activation_container, num_new_tokens, occurrence_index, num_prev, num_fut, transplant_strings)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\intervention\\contexts\\interleaving.py:96\u001b[0m, in \u001b[0;36mInterleavingTracer.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoker\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39m_envoy\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\tracing\\contexts\\tracer.py:25\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglobals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalTracingContext\n\u001b[0;32m     23\u001b[0m GlobalTracingContext\u001b[38;5;241m.\u001b[39mtry_deregister(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\venv\\Lib\\site-packages\\nnsight\\tracing\\contexts\\base.py:72\u001b[0m, in \u001b[0;36mContext.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m     69\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mstack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(graph\u001b[38;5;241m.\u001b[39mstack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], graph, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\durrc\\OneDrive\\Desktop\\mech_interp_work\\mech_interp_research\\activation_transplanting.py:722\u001b[0m, in \u001b[0;36mgenerate_with_transplanted_activity\u001b[1;34m(self, target_string, target_substring, source_token_index, activation_container, num_new_tokens, occurrence_index, num_prev, num_fut, transplant_strings)\u001b[0m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllama_config\u001b[38;5;241m.\u001b[39mnum_hidden_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllama\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39moutput[\n\u001b[0;32m    711\u001b[0m             :, target_token_idx \u001b[38;5;241m+\u001b[39m delta, :\n\u001b[0;32m    712\u001b[0m         ] \u001b[38;5;241m=\u001b[39m activation_container\u001b[38;5;241m.\u001b[39mget_activation(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    715\u001b[0m             label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_residual_output\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    716\u001b[0m         )\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_token = \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    720\u001b[0m     target_token_idx \u001b[38;5;241m+\u001b[39m delta,\n\u001b[0;32m    721\u001b[0m     activation_container\u001b[38;5;241m.\u001b[39mget_token_by_index(\n\u001b[1;32m--> 722\u001b[0m         target_token_idx \u001b[38;5;241m+\u001b[39m delta\n\u001b[0;32m    723\u001b[0m     )\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    724\u001b[0m )\n\u001b[0;32m    725\u001b[0m toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllama\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(cutoff_string)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    727\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_token = \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    728\u001b[0m     target_token_idx \u001b[38;5;241m+\u001b[39m delta,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    733\u001b[0m     ),\n\u001b[0;32m    734\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "outputs=tk.transplant_newline_activities(\n",
    "        source_strings=['Word Problem Setup: A woman has ten oranges when he leaves the market.\\n\\n She has '],\n",
    "        target_strings=['Word Problem Setup: A woman has ten oranges when he leaves the market.\\n\\n She has '],\n",
    "        num_new_tokens=10,\n",
    "        target_substring=\".\\n\\n\",\n",
    "        occurrence_index= 0,\n",
    "        num_prev = 0,\n",
    "        num_fut= 0,\n",
    "        transplant_strings= (\"residual\",),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting token activations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 16:54:10,082 eaa305d2-3b3e-49cc-8288-593753fe095c - RECEIVED: Your job has been received and is waiting approval.\n",
      "2025-03-14 16:54:11,607 eaa305d2-3b3e-49cc-8288-593753fe095c - APPROVED: Your job was approved and is waiting to be run.\n",
      "2025-03-14 16:54:13,479 eaa305d2-3b3e-49cc-8288-593753fe095c - RUNNING: Your job has started running.\n",
      "2025-03-14 16:54:19,099 eaa305d2-3b3e-49cc-8288-593753fe095c - COMPLETED: Your job has been completed.\n",
      "Downloading result: 100%|██████████| 4.62M/4.62M [00:00<00:00, 16.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_newline_indices [16]\n",
      "source_newline_index 16\n",
      "('.\\n\\n', 382)\n",
      "{}\n",
      "generating with transplant\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n",
      "source_token =  11 (' when', 994)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -4 .\n",
      "\n",
      "\n",
      "source_token =  12 (' he', 568)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -3 .\n",
      "\n",
      "\n",
      "source_token =  13 (' leaves', 11141)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -2 They\n",
      "source_token =  14 (' the', 279)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  -1  have\n",
      "source_token =  15 (' store', 3637)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  0 <|begin_of_text|>\n",
      "source_token =  16 ('.\\n\\n', 382)\n",
      "these are toks [128000, 11116, 22854, 19139, 25, 362, 893, 706, 5899, 1069, 14576, 994, 568, 11141, 279, 3637, 382, 382, 7009, 617] 11116\n",
      "target_token =  1 Word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 16:54:38,784 4f43751e-117a-4c53-ad48-b664cd88ab7b - RECEIVED: Your job has been received and is waiting approval.\n",
      "2025-03-14 16:54:43,241 4f43751e-117a-4c53-ad48-b664cd88ab7b - APPROVED: Your job was approved and is waiting to be run.\n",
      "2025-03-14 16:54:49,764 4f43751e-117a-4c53-ad48-b664cd88ab7b - RUNNING: Your job has started running.\n",
      "2025-03-14 16:54:57,709 4f43751e-117a-4c53-ad48-b664cd88ab7b - COMPLETED: Your job has been completed.\n",
      "Downloading result: 100%|██████████| 5.13M/5.13M [00:00<00:00, 7.89MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.11248883, 0.1583274 , 0.04535482, 0.08479982, 0.13980855,\n",
       "       0.03025266, 0.04424512, 0.04272186, 0.01677323, 0.32522765],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_simple_number_experiment(tk, num=10, number_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll see if we can read from this how many fruits there were "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets generate a bunch of random strings for each number in 1-10 \n",
    "\n",
    "we'll try to see if we can extract from this the placement of the vectors "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
