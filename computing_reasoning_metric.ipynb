{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d9d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/mech_interp_research/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import transformer_lens.utils as utils\n",
    "import hashlib\n",
    "import yaml \n",
    "import hashlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2dd02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [00:32<00:00, 16.41s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.1-8B into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = utils.get_device()\n",
    "\n",
    "reference_model_path = 'meta-llama/Llama-3.1-8B'\n",
    "baseline_model_path = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "\n",
    "baseline_model_hf = AutoModelForCausalLM.from_pretrained(baseline_model_path, torch_dtype=torch.bfloat16)\n",
    "baseline_model_tokenizer = AutoTokenizer.from_pretrained(baseline_model_path)\n",
    "\n",
    "baseline_model = HookedTransformer.from_pretrained_no_processing(\n",
    "    reference_model_path,\n",
    "    hf_model=baseline_model_hf,\n",
    "    tokenizer=baseline_model_tokenizer,\n",
    "    device=device,\n",
    "    move_to_device=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc84631",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8b8d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [\n",
    "  {\"role\": \"user\", \"content\": \"What's the fifth prime?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61902057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜><｜User｜>What's the fifth prime?<｜Assistant｜><think>\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.apply_chat_template(chat, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7137d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000, 128011, 3923, 596, 279, 18172, 10461, 30, 128012, 128013, 198]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.apply_chat_template(chat, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3113de75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 12.77it/s]\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    model.tokenizer.apply_chat_template(chat, add_generation_prompt=True, tokenize=False),\n",
    "    max_new_tokens=50,\n",
    "    do_sample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e331e972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜User｜>What's the fifth prime?<｜Assistant｜><think>\n",
      "To determine the fifth prime number, I'll start by listing the prime numbers in order.\n",
      "\n",
      "First, I know that 2 is the first prime number.\n",
      "\n",
      "Next, 3 is also a prime number since it has no divisors other than 1\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6302e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 128256])\n"
     ]
    }
   ],
   "source": [
    "logits = model(\n",
    "    model.tokenizer.apply_chat_template(chat, add_generation_prompt=True, tokenize=False),\n",
    "    return_type='logits',\n",
    ")\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e90eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = logits[0, -1, :].softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d45f71f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming `probs` is a tensor of probabilities and `model.tokenizer` is defined\n",
    "topk = 10  # Number of top tokens to visualize\n",
    "topk_probs, topk_indices = probs.topk(topk)  # Get top-k probabilities and their indices\n",
    "\n",
    "# Decode the token indices to get the corresponding tokens\n",
    "topk_tokens = [f\"{model.tokenizer.decode([idx])}, {idx}\" for idx in topk_indices]\n",
    "\n",
    "# Convert tensors to numpy arrays for visualization\n",
    "topk_probs = topk_probs.cpu().detach().numpy()\n",
    "topk_indices = topk_indices.cpu().detach().numpy()\n",
    "\n",
    "# Plot the bar chart\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.barh(topk_tokens, topk_probs, color='skyblue')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Tokens')\n",
    "plt.title('Top 10 Tokens with Highest Probabilities')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the highest probability at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0204ba",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "to do this rigorously \n",
    "\n",
    "compute probabilities over N (16, 32 prompts)\n",
    "\n",
    "and use the outputs over those \n",
    "this controls for different output probabilities between different prompts \n",
    "\n",
    "look at variance between prmopts to make sure that your metrics \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad66635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = [[1271], [1271, 1505], [1271, 8417], [334, 37942, 25]]\n",
    "neg_features = [[33413]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c24c69e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_string(neg_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ece0f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To\n",
      "To find\n",
      "To determine\n",
      "**Solution:\n"
     ]
    }
   ],
   "source": [
    "for feat in pos_features:\n",
    "    print(model.to_string(feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f0e3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60131d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42c47ea1",
   "metadata": {},
   "source": [
    "write a function which takes in a list of lists of tokens \n",
    "\n",
    "promtp = \"do this\"\n",
    "\n",
    "eg: \n",
    "pos_features = [\n",
    "    [12,],\n",
    "    [13, 128]\n",
    "]\n",
    "\n",
    "negative_feats = [...]\n",
    "\n",
    "log_prob(pos_feats) - log_prob(prompt+neg_feats) \n",
    "\n",
    "\n",
    "appends each to the end of a prompt, and returns their"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f887a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_feature_mode_metric(\n",
    "    model: HookedTransformer,\n",
    "    prompt: str,\n",
    "    pos_features: list[list[int]],\n",
    "    neg_features: list[list[int]],\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes:\n",
    "      - normalized probabilities for each feature sequence (sum to 1)\n",
    "      - unnormalized log-scores for each\n",
    "      - logit (log-odds) of producing any negative feature.\n",
    "    Uses model.to_tokens() for tokenization.\n",
    "    \"\"\"\n",
    "    device = model.cfg.device\n",
    "    # 1) Tokenize prompt with the built-in hook\n",
    "    #    (adds BOS if the model is configured to)\n",
    "    input_ids = model.to_tokens(prompt).to(device)\n",
    "\n",
    "    # 2) Score one feature sequence by accumulating log-probs\n",
    "    def sequence_score(feature: list[int]) -> torch.Tensor:\n",
    "        ctx = input_ids.clone()\n",
    "        total_log_prob = torch.tensor(0.0, device=device)\n",
    "        for tok in feature:\n",
    "            # run the model on the current context\n",
    "            logits, activations = model.run_with_cache(ctx) #turn off this \n",
    "            last_logits = logits[:, -1, :]  # [1, vocab_size]\n",
    "            log_probs = torch.log_softmax(last_logits, dim=-1)\n",
    "            total_log_prob = total_log_prob + log_probs[0, tok]\n",
    "            # append the ground-truth token to the context\n",
    "            ctx = torch.cat([ctx, torch.tensor([[tok]], device=device)], dim=1)\n",
    "        return total_log_prob\n",
    "\n",
    "    # 3) Compute scores for all features\n",
    "    all_features = pos_features + neg_features\n",
    "    scores = torch.stack([sequence_score(f) for f in all_features])  # (n+m,)\n",
    "\n",
    "    # 4) Softmax to get normalized probabilities\n",
    "    norm_probs = torch.softmax(scores, dim=0)                        # (n+m,)\n",
    "\n",
    "    # 5) Sum up the negative-feature mass & compute logit\n",
    "    num_pos   = len(pos_features)\n",
    "    neg_prob  = norm_probs[num_pos:].sum()\n",
    "    neg_logit = torch.log(neg_prob) - torch.log(1 - neg_prob)\n",
    "\n",
    "    return norm_probs, scores, neg_logit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0b36ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To\n",
      "To find\n",
      "To determine\n",
      "**Solution:\n",
      "\n",
      "\n",
      "\n",
      "Okay\n"
     ]
    }
   ],
   "source": [
    "pos_features = [[1271], [1271, 1505], [1271, 8417], [334, 37942, 25]]\n",
    "neg_features = [[33413]]\n",
    "\n",
    "for pf in pos_features:\n",
    "    print(model.to_string(pf))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "for nf in neg_features:\n",
    "    print(model.to_string(nf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f188d186",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 44.34 GiB of which 24.81 MiB is free. Process 2410955 has 44.31 GiB memory in use. Of the allocated memory 43.97 GiB is allocated by PyTorch, and 32.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m pos_features \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1271\u001b[39m], [\u001b[38;5;241m1271\u001b[39m, \u001b[38;5;241m1505\u001b[39m], [\u001b[38;5;241m1271\u001b[39m, \u001b[38;5;241m8417\u001b[39m], [\u001b[38;5;241m334\u001b[39m, \u001b[38;5;241m37942\u001b[39m, \u001b[38;5;241m25\u001b[39m]]\n\u001b[1;32m      3\u001b[0m neg_features \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m33413\u001b[39m]]\n\u001b[0;32m----> 5\u001b[0m norm_probs, scores, neg_logit \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_feature_mode_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_features\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalized probabilities:\u001b[39m\u001b[38;5;124m\"\u001b[39m, norm_probs)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnormalized log-scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores)\n",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m, in \u001b[0;36mcompute_feature_mode_metric\u001b[0;34m(model, prompt, pos_features, neg_features)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 3) Compute scores for all features\u001b[39;00m\n\u001b[1;32m     34\u001b[0m all_features \u001b[38;5;241m=\u001b[39m pos_features \u001b[38;5;241m+\u001b[39m neg_features\n\u001b[0;32m---> 35\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([sequence_score(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m all_features])  \u001b[38;5;66;03m# (n+m,)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 4) Softmax to get normalized probabilities\u001b[39;00m\n\u001b[1;32m     38\u001b[0m norm_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)                        \u001b[38;5;66;03m# (n+m,)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 3) Compute scores for all features\u001b[39;00m\n\u001b[1;32m     34\u001b[0m all_features \u001b[38;5;241m=\u001b[39m pos_features \u001b[38;5;241m+\u001b[39m neg_features\n\u001b[0;32m---> 35\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43msequence_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m all_features])  \u001b[38;5;66;03m# (n+m,)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 4) Softmax to get normalized probabilities\u001b[39;00m\n\u001b[1;32m     38\u001b[0m norm_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)                        \u001b[38;5;66;03m# (n+m,)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mcompute_feature_mode_metric.<locals>.sequence_score\u001b[0;34m(feature)\u001b[0m\n\u001b[1;32m     22\u001b[0m total_log_prob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m feature:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# run the model on the current context\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     logits, cache \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     last_logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# [1, vocab_size]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     log_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(last_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:694\u001b[0m, in \u001b[0;36mHookedTransformer.run_with_cache\u001b[0;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_with_cache\u001b[39m(\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mmodel_args, return_cache_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, remove_batch_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    679\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m     Union[ActivationCache, Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]],\n\u001b[1;32m    687\u001b[0m ]:\n\u001b[1;32m    688\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper around `run_with_cache` in HookedRootModule.\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    If return_cache_object is True, this will return an ActivationCache object, with a bunch of\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m    useful HookedTransformer specific methods, otherwise it will return a dictionary of\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;124;03m    activations as in HookedRootModule.\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m     out, cache_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_batch_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_batch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_cache_object:\n\u001b[1;32m    698\u001b[0m         cache \u001b[38;5;241m=\u001b[39m ActivationCache(cache_dict, \u001b[38;5;28mself\u001b[39m, has_batch_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m remove_batch_dim)\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/transformer_lens/hook_points.py:569\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, pos_slice, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m cache_dict, fwd, bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_caching_hooks(\n\u001b[1;32m    556\u001b[0m     names_filter,\n\u001b[1;32m    557\u001b[0m     incl_bwd,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    560\u001b[0m     pos_slice\u001b[38;5;241m=\u001b[39mpos_slice,\n\u001b[1;32m    561\u001b[0m )\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(\n\u001b[1;32m    564\u001b[0m     fwd_hooks\u001b[38;5;241m=\u001b[39mfwd,\n\u001b[1;32m    565\u001b[0m     bwd_hooks\u001b[38;5;241m=\u001b[39mbwd,\n\u001b[1;32m    566\u001b[0m     reset_hooks_end\u001b[38;5;241m=\u001b[39mreset_hooks_end,\n\u001b[1;32m    567\u001b[0m     clear_contexts\u001b[38;5;241m=\u001b[39mclear_contexts,\n\u001b[1;32m    568\u001b[0m ):\n\u001b[0;32m--> 569\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incl_bwd:\n\u001b[1;32m    571\u001b[0m         model_out\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:612\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    609\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    610\u001b[0m         )\n\u001b[0;32m--> 612\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/transformer_lens/components/transformer_block.py:160\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    153\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    154\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    156\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_normalization_before_and_after:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1_post(attn_out)\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/transformer_lens/components/abstract_attention.py:196\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    170\u001b[0m     query_input: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m     position_bias: Optional[Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 head_index pos kv_pos\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    188\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    shortformer_pos_embed is only used if self.cfg.positional_embedding_type == \"shortformer\", else defaults to None and is irrelevant. See HookedTransformerConfig for more details\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    past_kv_cache_entry is an optional entry of past keys and values for this layer, only relevant if generating text. Defaults to None\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    additive_attention_mask is an optional mask to add to the attention weights. Defaults to None.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    attention_mask is the attention mask for padded tokens. Defaults to None.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_qkv_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_kv_cache_entry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# Appends the new keys and values to the cached values, and automatically updates the cache\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         kv_cache_pos_offset \u001b[38;5;241m=\u001b[39m past_kv_cache_entry\u001b[38;5;241m.\u001b[39mpast_keys\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/transformer_lens/components/grouped_query_attention.py:127\u001b[0m, in \u001b[0;36mGroupedQueryAttention.calculate_qkv_matrices\u001b[0;34m(self, query_input, key_input, value_input)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the Q, K, and V matrices for grouped query attention.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03mThis function uses the unexpanded weights _W_K and _W_V to calculate K and V.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03mA tuple containing the Q, K, and V matrices with the specified shapes.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m attn_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    121\u001b[0m     complex_attn_linear\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_split_qkv_input \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_attn_in\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m simple_attn_linear\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    126\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_q(\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mattn_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_Q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_Q\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    130\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_k(\n\u001b[1;32m    131\u001b[0m     attn_fn(key_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_K, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_K)\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mungroup_grouped_query_attention\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m attn_fn(key_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_W_K, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b_K)\n\u001b[1;32m    134\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    135\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_v(\n\u001b[1;32m    136\u001b[0m     attn_fn(value_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_V, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_V)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mungroup_grouped_query_attention\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m attn_fn(value_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_W_V, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b_V)\n\u001b[1;32m    139\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/transformer_lens/utilities/attention.py:24\u001b[0m, in \u001b[0;36msimple_attn_linear\u001b[0;34m(input, w, b)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m b\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[1;32m     22\u001b[0m     b \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 24\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43meinops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhead_index d_model d_head -> (head_index d_head) d_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m b_ \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(b, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_index d_head -> (head_index d_head)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, w, b_)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], b\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], b\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/einops/einops.py:600\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrearrange\u001b[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths: Size) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrearrange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/einops/einops.py:532\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    530\u001b[0m     shape \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mshape(tensor)\n\u001b[1;32m    531\u001b[0m     recipe \u001b[38;5;241m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(axes_lengths), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(shape))\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_recipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhashable_axes_lengths\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EinopsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error while processing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-reduction pattern \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(reduction, pattern)\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/einops/einops.py:251\u001b[0m, in \u001b[0;36m_apply_recipe\u001b[0;34m(backend, recipe, tensor, reduction_type, axes_lengths)\u001b[0m\n\u001b[1;32m    249\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39madd_axes(tensor, n_axes\u001b[38;5;241m=\u001b[39mn_axes_w_added, pos2len\u001b[38;5;241m=\u001b[39madded_axes)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_shapes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/mech_interp_research/venv/lib/python3.10/site-packages/einops/_backends.py:93\u001b[0m, in \u001b[0;36mAbstractBackend.reshape\u001b[0;34m(self, x, shape)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreshape\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, shape):\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 44.34 GiB of which 24.81 MiB is free. Process 2410955 has 44.31 GiB memory in use. Of the allocated memory 43.97 GiB is allocated by PyTorch, and 32.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt       = \"<｜User｜>What is 8/4<｜Assistant｜><think>\\n\"\n",
    "pos_features = [[1271], [1271, 1505], [1271, 8417], [334, 37942, 25]]\n",
    "neg_features = [[33413]]\n",
    "\n",
    "norm_probs, scores, neg_logit = compute_feature_mode_metric(\n",
    "    model, prompt, pos_features, neg_features\n",
    ")\n",
    "\n",
    "print(\"Normalized probabilities:\", norm_probs)\n",
    "print(\"Unnormalized log-scores:\", scores)\n",
    "print(\"Negative-feature logit:\", neg_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ab916",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt       = \"<｜User｜>What is 8/4<｜Assistant｜><think>\\nOkay, I know 8/4=2\\n</think>s\"\n",
    "pos_features = [[1271], [1271, 1505], [1271, 8417], [334, 37942, 25]]\n",
    "neg_features = [[33413]]\n",
    "\n",
    "norm_probs, scores, neg_logit = compute_feature_mode_metric(\n",
    "    model, prompt, pos_features, neg_features\n",
    ")\n",
    "\n",
    "print(\"Normalized probabilities:\", norm_probs)\n",
    "print(\"Unnormalized log-scores:\", scores)\n",
    "print(\"Negative-feature logit:\", neg_logit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
